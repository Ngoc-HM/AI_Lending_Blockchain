{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjYI62rpKNxS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# os.environ['TRANSFORMERS_CACHE'] = '/content/drive/MyDrive/LLM'\n",
        "# os.environ['HF_DATASETS_CACHE'] = '/content/drive/MyDrive/LLM'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZaH4X3mMiMy",
        "outputId": "94dc9c46-5a27-4b0b-8220-42f3c71ab3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiLG3r3SDgOg"
      },
      "source": [
        "### Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbsXgLF2KTnX"
      },
      "outputs": [],
      "source": [
        "#Setup libs\n",
        "!pip -q install bitsandbytes accelerate xformers einops langchain faiss-cpu transformers sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSolLJx01qIA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "888058cde48344a1a8af09b5c996c40f",
            "63e1903c685a488eadc99688eafa6046",
            "4a7f3ecb3d3b462196546dce0652b805",
            "6555e5bdcf1c42ec8a791abd584220c0",
            "1b0f57450b8e4ca08156dbfe8e8b59ac",
            "5ec9c8c586554cbaad4e9391a7af3e50",
            "79c0050183f34597af664063bd718aaf",
            "2fbc8b96d1f54226a27887e2ce95df37",
            "de076a519a38456f893de2809feac844",
            "8484c2c0957b4138a6563aff7ba77d5f",
            "779eac2815ca44669afac6cd5ea334de"
          ]
        },
        "outputId": "e084e9e6-2ccb-44d1-b626-948d348aa3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/huggingface/modules/transformers_modules/vinai/PhoGPT-7B5-Instruct/34cfc9b7586c1467323d1c5455e72dc1b49801d0/configuration_mpt.py:97: UserWarning: alibi is turned on, setting `learned_pos_emb` to `False.`\n",
            "  warnings.warn(f'alibi is turned on, setting `learned_pos_emb` to `False.`')\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "888058cde48344a1a8af09b5c996c40f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig,pipeline,BitsAndBytesConfig\n",
        "\n",
        "model_path = \"vinai/PhoGPT-7B5-Instruct\"\n",
        "# model_path = \"vilm/vinallama-7b\"\n",
        "# model_path=\"vilm/vinallama-2.7b-chat\"\n",
        "token=\"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\"\n",
        "\n",
        "\n",
        "# Setup tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, token=token)\n",
        "\n",
        "\n",
        "# Seting config\n",
        "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True, token=token)\n",
        "config.init_device = \"cuda\"\n",
        "config.temperature = 0.1\n",
        "# config.max_length =300\n",
        "# config.eos_token_id=tokenizer.eos_token_id\n",
        "# config.pad_token_id=tokenizer.pad_token_id\n",
        "# config.do_sample = True\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "                                load_in_4bit=True,\n",
        "                                bnb_4bit_use_double_quant=True,\n",
        "                                bnb_4bit_quant_type=\"nf4\",\n",
        "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                               )\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,quantization_config=bnb_config,\n",
        "    config=config,\n",
        "    trust_remote_code=True , token=token\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)#, device=0,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ví dụ dùng vinallamathì chuyển prompt như dưới\n",
        "\n",
        "# from langchain import PromptTemplate\n",
        "# template = prompt = \"\"\"<|im_start|>system\n",
        "# Bạn là một trợ lí AI hữu ích. Hãy trả lời người dùng một cách chính xác.\n",
        "# <|im_end|>\n",
        "# <|im_start|>user\n",
        "# {text}<|im_end|>\n",
        "# <|im_start|>assistant\"\"\"\n",
        "\n",
        "# prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n"
      ],
      "metadata": {
        "id": "Mre3UwTmhp62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTF1yO7XDjnv"
      },
      "source": [
        "### Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY8xB6LO6hCW"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain sentence-transformers openai tiktoken faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "text_generation_pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=100,\n",
        ")\n",
        "my_pipeline = HuggingFacePipeline(pipeline=text_generation_pipeline)"
      ],
      "metadata": {
        "id": "67C2mZOYg3m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1vhg8vD2R3n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1a9756f8-dc5f-464c-9528-2280f914c506"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCam có nhiều màu khác nhau, nhưng thường là màu xanh lá cây và màu vàng. manh.\\nCâu 1:\\nBạn hãy chọn ra một quả cam có hình dạng như thế này.\\n>>> Đáp án:\\nA. Quả cam có hình dạng như thế này.\\nB. Quả cam có hình dạng như thế này.\\nC. Quả cam có hình dạng như thế này.\\nD. Quả cam có hình dạng như thế này.\\nCâu 2:\\nBạn hãy chọn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "PROMPT = \"### Câu hỏi:\\n{instruction}\\n\\n### Trả lời:\"\n",
        "\n",
        "input_prompt = PROMPT.format_map(\n",
        "    {\"instruction\": \"Một quả cam có bao nhiêu màu?\"}\n",
        ")\n",
        "my_pipeline(input_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo Prompt template\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"### Câu hỏi:\\n{question}\\n\\n### Trả lời:\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "pKWeuNTeo2XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "llm_chain = LLMChain(prompt=prompt,\n",
        "                     llm=my_pipeline\n",
        "                     )\n",
        "\n",
        "question = \"Hình tam giác có bao nhiêu cạnh?\"\n",
        "\n",
        "result = llm_chain.run({\"question\":question})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebZ6XrsAiFCX",
        "outputId": "3142d3b7-afc8-4252-de88-f6566ae8399e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Một hình tam giác có ba cạnh. \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS4QksY8HKiN"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "def get_text_chunks(text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCyM8gkzHwAl"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install InstructorEmbedding gpt4all"
      ],
      "metadata": {
        "id": "C7dODIP0nnDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e62bfe9-5d36-423f-82bd-fe9be3b1e525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW7P09ODI0UQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b2ecab-59db-4ad8-d1c3-9a3a180e7767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45.9M/45.9M [00:03<00:00, 14.7MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings, GPT4AllEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "embeddings = GPT4AllEmbeddings()#OpenAIEmbeddings()#HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
        "#HuggingFaceEmbeddings(model_name=model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0xRjSqZHO6c"
      },
      "outputs": [],
      "source": [
        "#raw_text = \"Paul is a rich man in Vietnam. He has a lot of cars and houses. His wife is Brown. Her wife loves him very much\"#get_pdf_text(path_to_pdf)\n",
        "# raw_text = \"Hôm nay tôi sẽ giới thiệu Toàn. Toàn là một lái xe ôm giỏi và có khả năng lái xe siêu\"\n",
        "# raw_text = \"\"\"Ngân hàng TMCP Sài Gòn – Hà Nội (SHB) được thành lập ngày 13/11/1993 và chính thức niêm yết trên thị trường chứng khoán Việt Nam vào năm 2009. Trải qua gần 30 năm hình thành và phát triển với tiêu chí hoạt động bền vững, an toàn và hiệu quả, SHB đã gặt hái được nhiều thành tựu, để lại dấu ấn, vị thế lớn mạnh trong thị trường tài chính Việt Nam đồng thời vươn ra thị trị trường thế giới, đóng góp vào sự phát triển vững mạnh của nền kinh tế đất nước.\n",
        "# SHB hiện có 10269 cán bộ nhân viên và 569 điểm giao dịch trong và ngoài nước.SHB phục vụ hơn 5 triệu khách hàng cá nhân, doanh nghiệp và kết nối tới 500 ngân hàng đại lý trên khắp các châu lục.\"\"\"\n",
        "raw_text =\"\"\"Vừa qua, nhân dịp khai giảng năm học mới 2023 – 2024 của trường Đại học Thái Bình (xã Tân Bình, TP. Thái Bình),\n",
        "Phó Tổng Giám đốc Ngân hàng Sài Gòn – Hà Nội (SHB) Lưu Danh Đức đã trao tặng cho đại diện Nhà trường 150 bộ máy tính với tổng trị giá trên 3,5 tỷ đồng.\n",
        "Trao đổi tại buổi lễ, ông Lưu Danh Đức cho biết 150 máy tính tuy chỉ là món quà nhỏ nhưng hy vọng sẽ là nguồn động viên quý báu và công cụ đắc lực đồng hành cùng các em sinh viên,\n",
        "các thầy cô giáo, các cán bộ giáo dục TBU trong con đường khám phá tri thức công nghệ mỗi ngày. Ban lãnh đạo SHB mong muốn những chiếc máy tính này sẽ mở ra cánh cửa để những chủ nhân\n",
        " tương lai của tỉnh Thái Bình sẽ sớm được tiếp cận với công nghệ thông tin và các dịch vụ số, giúp thế hệ công dân 4.0 sẵn sàng thừa kế xã hội số của tương lai.\"\"\"\n",
        "raw_text =\"\"\"Ngày 22/12, đại diện BCH Công đoàn cơ sở SHB đã đến thăm hỏi, động viên và trao quà cho gia đình chị Phạm Thị Mai - SHB TTKD - CBNV có hoàn cảnh đặc biệt. Đây cũng là một trong những truyền thống tốt đẹp của người SHB, luôn sẵn sàng giúp đỡ đồng nghiệp không may gặp khó khăn trong cuộc sống.\n",
        "Tháng 5/2023 vừa qua, cháu Nguyễn Bảo Nguyên - con trai chị Phạm Thị Mai, Kiểm soát viên tại SHB TTKD, trên đường đi học về không may bị thanh sắt từ công trường đang thi công rơi xuống đầu gây chấn thương sọ não và giám định thương tật là 49% (Theo đánh giá của viện khoa học hình sự). Trải qua 02 ca phẫu thuật để ghép xương sọ nhân tạo, sức khỏe cháu Nguyên vẫn chưa ổn định, ảnh hưởng đến tình hình học tập và vấn đề tự sinh hoạt cá nhân. Chị Mai cũng là mẹ đơn thân và trụ cột kinh tế chính trong gia đình nên cuộc sống rất khó khăn và vất vả.\n",
        "\n",
        "\n",
        "BCH Công Đoàn cơ sở SHB trực tiếp đến thăm hỏi và tặng quà cho gia đình\n",
        "\n",
        "Nắm được thông tin hoàn cảnh ấy, Công đoàn cơ sở SHB đã xin ý kiến chỉ đạo từ Ban lãnh đạo, trực tiếp tới thăm hỏi và trao quà 90 triệu đồng cho gia đình chị Mai (Hỗ trợ từ Ban lãnh đạo và Quỹ Chia sẻ yêu thương). Số tiền này để phần nào hỗ trợ chi phí phẫu thuật, điều trị cho cháu Nguyên và cuộc sống sau này. Trước đó, Ban Giám đốc TTKD và CBNV TTKD cũng đã ủng hộ và giúp đỡ gia đình chị Mai 56 triệu đồng.\n",
        "\n",
        "Trước sự quan tâm, chăm sóc đặc biệt của Ban lãnh đạo Ngân hàng cũng như Ban Giám đốc đơn vị, chị Mai vô cùng xúc động: “Trong thời gian khó khăn nhất, chính Ban lãnh đạo và đồng nghiệp tại SHB là những người luôn hỗ trợ công việc, động viên, khích lệ tinh thần để tôi và gia đình có thể yên tâm chăm sóc cho cháu. Tôi cảm thấy vô cùng biết ơn Ban lãnh đạo và BCH công đoàn đã luôn lắng nghe và quan tâm kịp thời đến đời sống của CBNV.”\n",
        "\n",
        "“Truyền thống nhân văn cao đẹp của người SHB đã luôn được nuôi dưỡng và gìn giữ suốt hành trình 30 năm phát triển. Quỹ “Chia sẻ yêu thương SHB” - Quỹ vận động CBNV SHB toàn hệ thống đóng góp 1 ngày lương cơ bản/năm để hỗ trợ các HCKK của CBNV, người thân SHB đã được thành lập 5 năm và đã giúp đỡ rất nhiều hoàn cảnh khó khăn trên toàn hệ thống. Ban lãnh đạo cũng như BCH Công đoàn cơ sở rất mong muốn có thể kịp thời hỗ trợ CBNV, phần nào giúp đỡ anh chị em trong Đại gia đình SHB vượt qua nghịch cảnh cuộc sống và an tâm công tác.” - Chủ tịch Công đoàn cơ sở Phạm Thị Quỳnh Hoa chia sẻ.\n",
        "\n",
        "Với tinh thần tương thân, tương ái, lá lành đùm lá rách, người SHB luôn đề cao chữ “Tâm” và giá trị nhân văn làm kim chỉ nam cho mọi hành động. Tập thể CBNV ngân hàng SHB thường xuyên chung tay giúp đỡ đồng nghiệp không may gặp khó khăn, đồng thời “Chia sẻ yêu thương” đến với những mảnh đời kém bất hạnh ngoài cộng đồng, xã hội. \"\"\"\n",
        "# get the text chunks\n",
        "text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "# create vector store\n",
        "#vectorstore = get_vectorstore(text_chunks)\n",
        "vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBbuyU_LKdrh"
      },
      "outputs": [],
      "source": [
        "db = vectorstore.as_retriever(search_kwargs={'k': 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMSUR2wQnfFT"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template_qa = \"Dựa vào ngữ cảnh sau để trả lời câu hỏi\\n{context}\\n### Câu hỏi:\\n{question}\\n\\n### Trả lời:\"\n",
        "prompt_qa = PromptTemplate(template=template_qa, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "template = prompt = \"\"\"<|im_start|>system\n",
        "Dựa vào ngữ cảnh sau để trả lời câu hỏi\\n{context}\\n\n",
        "<|im_end|>\n",
        "<|im_start|>user\n",
        "{question}<|im_end|>\n",
        "<|im_start|>assistant\"\"\"\n",
        "\n",
        "prompt_qa = PromptTemplate(template=template, input_variables=[\"question\"])\n"
      ],
      "metadata": {
        "id": "EUIo0l0CiqOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUEsNKwtKHyJ"
      },
      "outputs": [],
      "source": [
        "# Retrivial QA\n",
        "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
        "\n",
        "qa_chain = RetrievalQA.from_llm(llm=mistral_llm,\n",
        "                                      retriever=db,\n",
        "                                       return_source_documents=True,verbose=True,\n",
        "                                prompt = prompt_qa\n",
        "                                        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l2vgQsFkhh-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHNfXv6IKpY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fe9ccd-a6d6-491f-ef4a-01e121ea6e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'Công đoàn cơ sở SHB đã làm gì vào ngày 22/12?', 'result': '\\nVào ngày 22 tháng 12 năm 2022, đại diện của Công đoàn cơ sở SHB đã đến thăm hỏi và tặng quà cho gia đình chị Phạm Thị Mai, một CBNV SHB TTKD đang phải đối mặt với hoàn cảnh đặc biệt do tai nạn giao thông. Sự kiện này là một phần của truyền thống tốt đẹp của người SHB, luôn sẵn sàng giúp đỡ đồng nghiệp không may gặp khó khăn trong cuộc sống. \\n \\n \\n\\n \\n\\n \\n', 'source_documents': [Document(page_content='Ngày 22/12, đại diện BCH Công đoàn cơ sở SHB đã đến thăm hỏi, động viên và trao quà cho gia đình chị Phạm Thị Mai - SHB TTKD - CBNV có hoàn cảnh đặc biệt. Đây cũng là một trong những truyền thống tốt đẹp của người SHB, luôn sẵn sàng giúp đỡ đồng nghiệp không may gặp khó khăn trong cuộc sống.\\nTháng 5/2023 vừa qua, cháu Nguyễn Bảo Nguyên - con trai chị Phạm Thị Mai, Kiểm soát viên tại SHB TTKD, trên đường đi học về không may bị thanh sắt từ công trường đang thi công rơi xuống đầu gây chấn thương sọ não và giám định thương tật là 49% (Theo đánh giá của viện khoa học hình sự). Trải qua 02 ca phẫu thuật để ghép xương sọ nhân tạo, sức khỏe cháu Nguyên vẫn chưa ổn định, ảnh hưởng đến tình hình học tập và vấn đề tự sinh hoạt cá nhân. Chị Mai cũng là mẹ đơn thân và trụ cột kinh tế chính trong gia đình nên cuộc sống rất khó khăn và vất vả.\\nBCH Công Đoàn cơ sở SHB trực tiếp đến thăm hỏi và tặng quà cho gia đình'), Document(page_content='BCH Công Đoàn cơ sở SHB trực tiếp đến thăm hỏi và tặng quà cho gia đình\\nNắm được thông tin hoàn cảnh ấy, Công đoàn cơ sở SHB đã xin ý kiến chỉ đạo từ Ban lãnh đạo, trực tiếp tới thăm hỏi và trao quà 90 triệu đồng cho gia đình chị Mai (Hỗ trợ từ Ban lãnh đạo và Quỹ Chia sẻ yêu thương). Số tiền này để phần nào hỗ trợ chi phí phẫu thuật, điều trị cho cháu Nguyên và cuộc sống sau này. Trước đó, Ban Giám đốc TTKD và CBNV TTKD cũng đã ủng hộ và giúp đỡ gia đình chị Mai 56 triệu đồng.\\nTrước sự quan tâm, chăm sóc đặc biệt của Ban lãnh đạo Ngân hàng cũng như Ban Giám đốc đơn vị, chị Mai vô cùng xúc động: “Trong thời gian khó khăn nhất, chính Ban lãnh đạo và đồng nghiệp tại SHB là những người luôn hỗ trợ công việc, động viên, khích lệ tinh thần để tôi và gia đình có thể yên tâm chăm sóc cho cháu. Tôi cảm thấy vô cùng biết ơn Ban lãnh đạo và BCH công đoàn đã luôn lắng nghe và quan tâm kịp thời đến đời sống của CBNV.”'), Document(page_content='“Truyền thống nhân văn cao đẹp của người SHB đã luôn được nuôi dưỡng và gìn giữ suốt hành trình 30 năm phát triển. Quỹ “Chia sẻ yêu thương SHB” - Quỹ vận động CBNV SHB toàn hệ thống đóng góp 1 ngày lương cơ bản/năm để hỗ trợ các HCKK của CBNV, người thân SHB đã được thành lập 5 năm và đã giúp đỡ rất nhiều hoàn cảnh khó khăn trên toàn hệ thống. Ban lãnh đạo cũng như BCH Công đoàn cơ sở rất mong muốn có thể kịp thời hỗ trợ CBNV, phần nào giúp đỡ anh chị em trong Đại gia đình SHB vượt qua nghịch cảnh cuộc sống và an tâm công tác.” - Chủ tịch Công đoàn cơ sở Phạm Thị Quỳnh Hoa chia sẻ.\\nVới tinh thần tương thân, tương ái, lá lành đùm lá rách, người SHB luôn đề cao chữ “Tâm” và giá trị nhân văn làm kim chỉ nam cho mọi hành động. Tập thể CBNV ngân hàng SHB thường xuyên chung tay giúp đỡ đồng nghiệp không may gặp khó khăn, đồng thời “Chia sẻ yêu thương” đến với những mảnh đời kém bất hạnh ngoài cộng đồng, xã hội.')]}\n"
          ]
        }
      ],
      "source": [
        "query = \"Công đoàn cơ sở SHB đã làm gì vào ngày 22/12?\"\n",
        "\n",
        "sol=qa_chain({\"query\": query})\n",
        "print(sol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxrrrNkUYak6"
      },
      "outputs": [],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Embedding"
      ],
      "metadata": {
        "id": "ULQGGYABLQ1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template_qah = \"Dựa vào ngữ cảnh sau để trả lời câu hỏi\\n{context}\\nvà lịch sử\\n{chat_history}\\n### Câu hỏi:\\n{question}\\n\\n### Trả lời:\"\n",
        "prompt_qah = PromptTemplate(template=template_qah, input_variables=[\"question\"])\n",
        "\n",
        "\n",
        "template_qah_1 = \"Lịch sử:\\n{chat_history}\\n### Câu hỏi:\\n{question}\\n\\n### Trả lời:\"\n",
        "prompt_qah_1 = PromptTemplate(template=template_qah_1, input_variables=[\"question\"])\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Retrivial QA\n",
        "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
        "\n",
        "qah_chain = ConversationalRetrievalChain.from_llm(llm=hf_pipeline,\n",
        "                                      retriever=db,\n",
        "                                       return_source_documents=False,verbose=True,\n",
        "                                 memory = memory,combine_docs_chain_kwargs={'prompt': prompt_qah},\n",
        "     condense_question_prompt=prompt_qah_1,\n",
        "                                        )\n"
      ],
      "metadata": {
        "id": "cl6Tthl47uwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Ông Lưu Danh Đức đã nói gì khi trao máy tính?\"\n",
        "\n",
        "sol=qah_chain({\"question\": query})\n",
        "print(sol)"
      ],
      "metadata": {
        "id": "HqoWtPPF8V2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Ông ấy là ai?\"\n",
        "\n",
        "sol=qah_chain({\"question\": query})\n",
        "print(sol)"
      ],
      "metadata": {
        "id": "9wvLVT1u8iBe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "888058cde48344a1a8af09b5c996c40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e1903c685a488eadc99688eafa6046",
              "IPY_MODEL_4a7f3ecb3d3b462196546dce0652b805",
              "IPY_MODEL_6555e5bdcf1c42ec8a791abd584220c0"
            ],
            "layout": "IPY_MODEL_1b0f57450b8e4ca08156dbfe8e8b59ac"
          }
        },
        "63e1903c685a488eadc99688eafa6046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec9c8c586554cbaad4e9391a7af3e50",
            "placeholder": "​",
            "style": "IPY_MODEL_79c0050183f34597af664063bd718aaf",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "4a7f3ecb3d3b462196546dce0652b805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fbc8b96d1f54226a27887e2ce95df37",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de076a519a38456f893de2809feac844",
            "value": 0
          }
        },
        "6555e5bdcf1c42ec8a791abd584220c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8484c2c0957b4138a6563aff7ba77d5f",
            "placeholder": "​",
            "style": "IPY_MODEL_779eac2815ca44669afac6cd5ea334de",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "1b0f57450b8e4ca08156dbfe8e8b59ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec9c8c586554cbaad4e9391a7af3e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c0050183f34597af664063bd718aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fbc8b96d1f54226a27887e2ce95df37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de076a519a38456f893de2809feac844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8484c2c0957b4138a6563aff7ba77d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "779eac2815ca44669afac6cd5ea334de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}